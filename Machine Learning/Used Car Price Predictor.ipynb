{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Used Car Price Predictor\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Rusty Bargain used car sales service is developing an app to attract new customers. In that app, you can quickly find out the market value of your car. You have access to historical data: technical specifications, trim versions, and prices. You need to build the model to determine the value. \n",
    "\n",
    "Rusty Bargain is interested in:\n",
    "\n",
    "- the quality of the prediction;\n",
    "- the speed of the prediction;\n",
    "- the time required for training\n",
    "\n",
    "## Table of Contents\n",
    "<a href='#Data Preparation'>Data Preparation</a>\n",
    "\n",
    "<a href='#Model Development'>Model Development</a>\n",
    "\n",
    "<a href='#Model Analysis'>Model Analysis</a>\n",
    "\n",
    "<a href='#Overall Conclusion'>Overall Conclusion</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Data Preparation'></a>\n",
    "## Data Preparation\n",
    "\n",
    "### General Data Information\n",
    "\n",
    "Initially, a general look at the data is performed and the necessary libraries are imported. Since the target attribute is numerical, regression libraries are imported for the various machine learning models, including for gradient boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import timeit\n",
    "import warnings\n",
    "from scipy import stats as st\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateCrawled</th>\n",
       "      <th>Price</th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Power</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>NotRepaired</th>\n",
       "      <th>DateCreated</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>LastSeen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>24/03/2016 11:52</td>\n",
       "      <td>480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "      <td>manual</td>\n",
       "      <td>0</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>70435</td>\n",
       "      <td>07/04/2016 03:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>24/03/2016 10:58</td>\n",
       "      <td>18300</td>\n",
       "      <td>coupe</td>\n",
       "      <td>2011</td>\n",
       "      <td>manual</td>\n",
       "      <td>190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125000</td>\n",
       "      <td>5</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>audi</td>\n",
       "      <td>yes</td>\n",
       "      <td>24/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>66954</td>\n",
       "      <td>07/04/2016 01:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>14/03/2016 12:52</td>\n",
       "      <td>9800</td>\n",
       "      <td>suv</td>\n",
       "      <td>2004</td>\n",
       "      <td>auto</td>\n",
       "      <td>163</td>\n",
       "      <td>grand</td>\n",
       "      <td>125000</td>\n",
       "      <td>8</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>jeep</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>90480</td>\n",
       "      <td>05/04/2016 12:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>17/03/2016 16:54</td>\n",
       "      <td>1500</td>\n",
       "      <td>small</td>\n",
       "      <td>2001</td>\n",
       "      <td>manual</td>\n",
       "      <td>75</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>6</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>17/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>91074</td>\n",
       "      <td>17/03/2016 17:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>31/03/2016 17:25</td>\n",
       "      <td>3600</td>\n",
       "      <td>small</td>\n",
       "      <td>2008</td>\n",
       "      <td>manual</td>\n",
       "      <td>69</td>\n",
       "      <td>fabia</td>\n",
       "      <td>90000</td>\n",
       "      <td>7</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>skoda</td>\n",
       "      <td>no</td>\n",
       "      <td>31/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>60437</td>\n",
       "      <td>06/04/2016 10:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DateCrawled  Price VehicleType  RegistrationYear Gearbox  Power  \\\n",
       "0  24/03/2016 11:52    480         NaN              1993  manual      0   \n",
       "1  24/03/2016 10:58  18300       coupe              2011  manual    190   \n",
       "2  14/03/2016 12:52   9800         suv              2004    auto    163   \n",
       "3  17/03/2016 16:54   1500       small              2001  manual     75   \n",
       "4  31/03/2016 17:25   3600       small              2008  manual     69   \n",
       "\n",
       "   Model  Mileage  RegistrationMonth  FuelType       Brand NotRepaired  \\\n",
       "0   golf   150000                  0    petrol  volkswagen         NaN   \n",
       "1    NaN   125000                  5  gasoline        audi         yes   \n",
       "2  grand   125000                  8  gasoline        jeep         NaN   \n",
       "3   golf   150000                  6    petrol  volkswagen          no   \n",
       "4  fabia    90000                  7  gasoline       skoda          no   \n",
       "\n",
       "        DateCreated  NumberOfPictures  PostalCode          LastSeen  \n",
       "0  24/03/2016 00:00                 0       70435  07/04/2016 03:16  \n",
       "1  24/03/2016 00:00                 0       66954  07/04/2016 01:46  \n",
       "2  14/03/2016 00:00                 0       90480  05/04/2016 12:47  \n",
       "3  17/03/2016 00:00                 0       91074  17/03/2016 17:40  \n",
       "4  31/03/2016 00:00                 0       60437  06/04/2016 10:17  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/datasets/car_data.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 354369 entries, 0 to 354368\n",
      "Data columns (total 16 columns):\n",
      "DateCrawled          354369 non-null object\n",
      "Price                354369 non-null int64\n",
      "VehicleType          316879 non-null object\n",
      "RegistrationYear     354369 non-null int64\n",
      "Gearbox              334536 non-null object\n",
      "Power                354369 non-null int64\n",
      "Model                334664 non-null object\n",
      "Mileage              354369 non-null int64\n",
      "RegistrationMonth    354369 non-null int64\n",
      "FuelType             321474 non-null object\n",
      "Brand                354369 non-null object\n",
      "NotRepaired          283215 non-null object\n",
      "DateCreated          354369 non-null object\n",
      "NumberOfPictures     354369 non-null int64\n",
      "PostalCode           354369 non-null int64\n",
      "LastSeen             354369 non-null object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 43.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are missing values present in the `VehicleType`, `Gearbox`, `Model`, `FuelType`, and `NotRepaired` attributes. These also happen to be the categorical features in the dataset.\n",
    "\n",
    "### Missing Values\n",
    "\n",
    "Since the missing values are all in the categorical features, they will initially be replaced with an 'unknown' value since this data will be used for all the iterations of the machine learning models, thus there will be a minimal difference in attempting to input a useful value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill all missing values with an unknown value\n",
    "data.fillna('unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`NotRepaired`**\n",
    "\n",
    "Since `NotRepaired` is intended to be a yes/no response, the values in it are converted to 1s, 0s, or 0.5s (due to the unknown responses) to change it to a numerical feature to prevent it from having to be one-hot encoded later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function returns a 0, 0.5, or 1 for the three options for the NotRepaired column\n",
    "def NotRepairedNumbering(value):\n",
    "    if value == 'yes':\n",
    "        return 1\n",
    "    elif value == 'no':\n",
    "        return 0\n",
    "    else:\n",
    "        return 0.5\n",
    "    \n",
    "data['NotRepaired'] = data['NotRepaired'].apply(NotRepairedNumbering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Features\n",
    "\n",
    "There are three attributes, `DateCrawled`, `DateCreated`, and `LastSeen` that are dates and times applicable to the dataset. Although these could be converted to a datetime datatype, these features are specific to information regarding the user profile posting the ad and would not be expected to have an impact on price of the vehicle, with the exception of potentially a seasonal impact which will not be evaluated as part of this project. As a result, these columns can be removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['DateCrawled', 'DateCreated', 'LastSeen'] , axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n",
    "\n",
    "In order for several of the models (linear regression, XGBoost, etc.) to be developed, the categorical features in the dataset must be one-hot encoded (OHE) to assign a numerical value to each feature. Additionally, the categorical features are converted to the category data type to allow for model training further down the line.\n",
    "\n",
    "It is noted that the original dataset will be maintained since several of the models (i.e., CatBoost) are able to accept the categorical data as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of categorical features\n",
    "categorical_features = ['VehicleType', 'Gearbox', 'Model', 'FuelType', 'Brand']\n",
    "\n",
    "#Converts data type from object to category\n",
    "for feature in categorical_features:\n",
    "    data[feature] = data[feature].astype('category')\n",
    "\n",
    "#OHE categorical features\n",
    "data_ohe = pd.get_dummies(data, drop_first = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Separation\n",
    "\n",
    "The original dataset, and the OHE dataset are separated into a training, validation, and testing dataset at a 3:1:1 ratio, respectively. Subsequently, each of these datasets can be separated into the features and targets, with the `Price` being the sole target. The size of each dataset is printed to verify a correct split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits the OHE dataset into 60% training, 40% leftover\n",
    "data_train_ohe, data_valid_test_ohe = train_test_split(data_ohe, test_size = 0.4, random_state=12345)\n",
    "#Splits the leftover OHE dataset into 50% validating, 50% testing for 20%/20% overall\n",
    "data_valid_ohe, data_test_ohe = train_test_split(data_valid_test_ohe, test_size = 0.5, random_state=12345)\n",
    "\n",
    "#Splits the original dataset into 60% training, 40% leftover\n",
    "data_train, data_valid_test = train_test_split(data, test_size = 0.4, random_state=12345)\n",
    "#Splits the leftover dataset into 50% validating, 50% testing for 20%/20% overall\n",
    "data_valid, data_test = train_test_split(data_valid_test, test_size = 0.5, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size: (212621, 313)\n",
      "Validation Size: (70874, 313)\n",
      "Testing Size: (70874, 313)\n"
     ]
    }
   ],
   "source": [
    "#Creates features and targets of each OHE dataset\n",
    "features_train_ohe = data_train_ohe.drop(['Price'], axis=1)\n",
    "target_train_ohe = data_train_ohe['Price']\n",
    "print(\"Training Size: {}\".format(features_train_ohe.shape))\n",
    "\n",
    "features_valid_ohe = data_valid_ohe.drop(['Price'], axis=1)\n",
    "target_valid_ohe = data_valid_ohe['Price']\n",
    "print(\"Validation Size: {}\".format(features_valid_ohe.shape))\n",
    "\n",
    "features_test_ohe = data_test_ohe.drop(['Price'], axis=1)\n",
    "target_test_ohe = data_test_ohe['Price']\n",
    "print(\"Testing Size: {}\".format(features_test_ohe.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size: (212621, 12)\n",
      "Validation Size: (70874, 12)\n",
      "Testing Size: (70874, 12)\n"
     ]
    }
   ],
   "source": [
    "#Creates features and targets of each original dataset\n",
    "features_train = data_train.drop(['Price'], axis=1)\n",
    "target_train = data_train['Price']\n",
    "print(\"Training Size: {}\".format(features_train.shape))\n",
    "\n",
    "features_valid = data_valid.drop(['Price'], axis=1)\n",
    "target_valid = data_valid['Price']\n",
    "print(\"Validation Size: {}\".format(features_valid.shape))\n",
    "\n",
    "features_test = data_test.drop(['Price'], axis=1)\n",
    "target_test = data_test['Price']\n",
    "print(\"Testing Size: {}\".format(features_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "Now that all missing values have been resolved, the data separated into training, validation, and testing datasets, and the features and targets defined, the models can be created, trained, and analyzed.\n",
    "\n",
    "<a id='Model Development'></a>\n",
    "## Model Development\n",
    "\n",
    "### Evaluation Criteria\n",
    "\n",
    "The evaluation criteria for the selected models will be the root mean squared error (RMSE) metric. Various hyperparameters will be tuned for the decision tree and random forest models, as well as for the models that implement gradient boosting. A linear regression model will be trained and tested as a sanity check model due to its simplicity, which will be used to compare against the results of the other models.\n",
    "\n",
    "Since the model training and prediction time are crucial in determining the ideal model, these two time frames will be displayed for each model iteration completed, in addition to the model's RMSE. Initially, the linear regression is trained and validated, with the RMSE for that being considered a baseline for selecting the best iteration of each type of model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time:\n",
      "CPU times: user 18.8 s, sys: 7.9 s, total: 26.7 s\n",
      "Wall time: 26.7 s\n",
      "\n",
      "Prediction Time:\n",
      "CPU times: user 132 ms, sys: 113 ms, total: 245 ms\n",
      "Wall time: 199 ms\n",
      "\n",
      "The RMSE for the linear regression model is 3146.\n"
     ]
    }
   ],
   "source": [
    "#Creates a linear regression model and trains it against the OHE training dataset. The RMSE is determined from the validation dataset\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "#Processing time is printed for both training and prediction\n",
    "print('Training Time:')\n",
    "%time lr_model.fit(features_train_ohe, target_train_ohe)\n",
    "print('')\n",
    "print('Prediction Time:')\n",
    "%time lr_prediction = lr_model.predict(features_valid_ohe)\n",
    "print('')\n",
    "print('The RMSE for the linear regression model is {:.0f}.'.format(mean_squared_error(target_valid_ohe, lr_prediction)**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sets the RMSE of the linear regression model to a baseline variable for use later\n",
    "baseline_RMSE = mean_squared_error(target_valid_ohe, lr_prediction)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree**\n",
    "\n",
    "A decision tree model is also trained for various depths. Again, the time required to train and predict the RMSE is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with max depth 5\n",
      "Training Time:\n",
      "CPU times: user 2.76 s, sys: 137 ms, total: 2.9 s\n",
      "Wall time: 2.91 s\n",
      "\n",
      "Prediction Time:\n",
      "CPU times: user 69.7 ms, sys: 62.7 ms, total: 132 ms\n",
      "Wall time: 132 ms\n",
      "\n",
      "The model RMSE Score: 2543\n",
      "\n",
      "Decision Tree with max depth 6\n",
      "Training Time:\n",
      "CPU times: user 3.32 s, sys: 112 ms, total: 3.43 s\n",
      "Wall time: 3.44 s\n",
      "\n",
      "Prediction Time:\n",
      "CPU times: user 58.7 ms, sys: 75.5 ms, total: 134 ms\n",
      "Wall time: 138 ms\n",
      "\n",
      "The model RMSE Score: 2413\n",
      "\n",
      "Decision Tree with max depth 7\n",
      "Training Time:\n",
      "CPU times: user 3.83 s, sys: 128 ms, total: 3.96 s\n",
      "Wall time: 3.97 s\n",
      "\n",
      "Prediction Time:\n",
      "CPU times: user 65.9 ms, sys: 71.3 ms, total: 137 ms\n",
      "Wall time: 137 ms\n",
      "\n",
      "The model RMSE Score: 2299\n",
      "\n",
      "Decision Tree with max depth 8\n",
      "Training Time:\n",
      "CPU times: user 4.24 s, sys: 131 ms, total: 4.37 s\n",
      "Wall time: 4.48 s\n",
      "\n",
      "Prediction Time:\n",
      "CPU times: user 67 ms, sys: 66.4 ms, total: 133 ms\n",
      "Wall time: 133 ms\n",
      "\n",
      "The model RMSE Score: 2221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loops through a max_depth from 5 to 8. Calculates RMSE Score for each and prints the processing time for training and predicting\n",
    "for depth in range (5,9):\n",
    "    print('Decision Tree with max depth {}'.format(depth))\n",
    "    dt_model = DecisionTreeRegressor(max_depth=depth, random_state=12345)\n",
    "    print('Training Time:')\n",
    "    %time dt_model.fit(features_train_ohe, target_train_ohe)\n",
    "    print('')\n",
    "    print('Prediction Time:')\n",
    "    %time dt_prediction = dt_model.predict(features_valid_ohe)\n",
    "    print('')\n",
    "    print(\"The model RMSE Score: {:.0f}\".format(mean_squared_error(target_valid_ohe, dt_prediction)**0.5))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree models are all significantly better quality than the linear regression model while also taking a short amount of processing time for training and prediction.\n",
    "\n",
    "### Hyperparameter Tuning\n",
    "\n",
    "**LightGBM**\n",
    "\n",
    "The first gradient boosting model that will be trained and tested is LightGBM. For this model, the hyperparameters of `learning_rate`, `iterations`, and `depth` are varied. In order to easily select the best hyperparameters based on the RMSE, the initial RMSE is compared to the linear regression, with the lowest RMSE being selected as the 'best' RMSE. All subsequent model RMSEs are then evaluated against the 'best' RMSE with the best RMSE and the hyperparameters required to get that RMSE printed at the end of all the model iterations. This algorithm is used for all of the hyperparameter tuning for the gradient boosting models.\n",
    "\n",
    "The LightGBM library accepts categorical features as-is, so no modifications need done to address these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM with learning rate: 1.0, n-estimators: 100, max tree depth: 10\n",
      "Training Time:\n",
      "CPU times: user 1.79 s, sys: 27.3 ms, total: 1.82 s\n",
      "Wall time: 1.89 s\n",
      "Prediction Time:\n",
      "CPU times: user 438 ms, sys: 3.55 ms, total: 441 ms\n",
      "Wall time: 444 ms\n",
      "RMSE: 1903\n",
      "\n",
      "\n",
      "LightGBM with learning rate: 1.0, n-estimators: 100, max tree depth: 8\n",
      "Training Time:\n",
      "CPU times: user 1.77 s, sys: 48.6 ms, total: 1.82 s\n",
      "Wall time: 1.83 s\n",
      "Prediction Time:\n",
      "CPU times: user 450 ms, sys: 7.9 ms, total: 457 ms\n",
      "Wall time: 460 ms\n",
      "RMSE: 1889\n",
      "\n",
      "\n",
      "LightGBM with learning rate: 1.0, n-estimators: 100, max tree depth: 6\n",
      "Training Time:\n",
      "CPU times: user 1.98 s, sys: 31.1 ms, total: 2.01 s\n",
      "Wall time: 2.11 s\n",
      "Prediction Time:\n",
      "CPU times: user 556 ms, sys: 3.43 ms, total: 560 ms\n",
      "Wall time: 563 ms\n",
      "RMSE: 1889\n",
      "\n",
      "\n",
      "LightGBM with learning rate: 1.0, n-estimators: 50, max tree depth: 10\n",
      "Training Time:\n",
      "CPU times: user 1.23 s, sys: 45.2 ms, total: 1.27 s\n",
      "Wall time: 1.28 s\n",
      "Prediction Time:\n",
      "CPU times: user 263 ms, sys: 0 ns, total: 263 ms\n",
      "Wall time: 266 ms\n",
      "RMSE: 1899\n",
      "\n",
      "\n",
      "LightGBM with learning rate: 1.0, n-estimators: 50, max tree depth: 8\n",
      "Training Time:\n",
      "CPU times: user 1.28 s, sys: 27.7 ms, total: 1.3 s\n",
      "Wall time: 1.31 s\n",
      "Prediction Time:\n",
      "CPU times: user 275 ms, sys: 0 ns, total: 275 ms\n",
      "Wall time: 278 ms\n",
      "RMSE: 1886\n",
      "\n",
      "\n",
      "LightGBM with learning rate: 1.0, n-estimators: 50, max tree depth: 6\n",
      "Training Time:\n",
      "CPU times: user 1.37 s, sys: 35.9 ms, total: 1.4 s\n",
      "Wall time: 1.41 s\n",
      "Prediction Time:\n",
      "CPU times: user 295 ms, sys: 0 ns, total: 295 ms\n",
      "Wall time: 298 ms\n",
      "RMSE: 1902\n",
      "\n",
      "\n",
      "LightGBM with learning rate: 0.5, n-estimators: 100, max tree depth: 10\n",
      "Training Time:\n",
      "CPU times: user 1.73 s, sys: 26.9 ms, total: 1.76 s\n",
      "Wall time: 1.76 s\n",
      "Prediction Time:\n",
      "CPU times: user 409 ms, sys: 0 ns, total: 409 ms\n",
      "Wall time: 412 ms\n",
      "RMSE: 1776\n",
      "\n",
      "\n",
      "LightGBM with learning rate: 0.5, n-estimators: 100, max tree depth: 8\n",
      "Training Time:\n",
      "CPU times: user 1.81 s, sys: 26.6 ms, total: 1.83 s\n",
      "Wall time: 1.84 s\n",
      "Prediction Time:\n",
      "CPU times: user 434 ms, sys: 0 ns, total: 434 ms\n",
      "Wall time: 437 ms\n",
      "RMSE: 1775\n",
      "\n",
      "\n",
      "LightGBM with learning rate: 0.5, n-estimators: 100, max tree depth: 6\n",
      "Training Time:\n",
      "CPU times: user 1.88 s, sys: 35 ms, total: 1.91 s\n",
      "Wall time: 1.92 s\n",
      "Prediction Time:\n",
      "CPU times: user 527 ms, sys: 6.12 ms, total: 533 ms\n",
      "Wall time: 535 ms\n",
      "RMSE: 1777\n",
      "\n",
      "\n",
      "LightGBM with learning rate: 0.5, n-estimators: 50, max tree depth: 10\n",
      "Training Time:\n",
      "CPU times: user 1.21 s, sys: 32.3 ms, total: 1.25 s\n",
      "Wall time: 1.25 s\n",
      "Prediction Time:\n",
      "CPU times: user 248 ms, sys: 8.17 ms, total: 256 ms\n",
      "Wall time: 255 ms\n",
      "RMSE: 1790\n",
      "\n",
      "\n",
      "LightGBM with learning rate: 0.5, n-estimators: 50, max tree depth: 8\n",
      "Training Time:\n",
      "CPU times: user 1.23 s, sys: 49.4 ms, total: 1.28 s\n",
      "Wall time: 1.28 s\n",
      "Prediction Time:\n",
      "CPU times: user 272 ms, sys: 3.87 ms, total: 276 ms\n",
      "Wall time: 279 ms\n",
      "RMSE: 1796\n",
      "\n",
      "\n",
      "LightGBM with learning rate: 0.5, n-estimators: 50, max tree depth: 6\n",
      "Training Time:\n",
      "CPU times: user 1.22 s, sys: 40.8 ms, total: 1.27 s\n",
      "Wall time: 1.27 s\n",
      "Prediction Time:\n",
      "CPU times: user 275 ms, sys: 3.82 ms, total: 278 ms\n",
      "Wall time: 282 ms\n",
      "RMSE: 1802\n",
      "\n",
      "\n",
      "The best RMSE is 1775, which are from the following parameters - learning rate: 0.5, n-estimators: 100, max tree depth: 8\n"
     ]
    }
   ],
   "source": [
    "#Creates tuples of the various hyperparameter combinations\n",
    "LGBM_params = [(learning_rate, iterations, depth) for learning_rate in [x/2 for x in range(1, 3)] for iterations in range(50, 101, 50) for depth in range(6, 11, 2)]\n",
    "\n",
    "#Sets initial values for the best score and parameters\n",
    "best_LGBM_parameters = [0, 0, 0]\n",
    "best_LGBM_RMSE = baseline_RMSE\n",
    "\n",
    "#Loops through each combination of hyperparameters. For each combination, the training time and prediction time for the model\n",
    "#is printed. RMSE is determined from the validation set\n",
    "for learning_rate, iterations, depth in reversed(LGBM_params):\n",
    "    print('LightGBM with learning rate: {}, n-estimators: {}, max tree depth: {}'.format(learning_rate, iterations, depth))\n",
    "\n",
    "    LGBM_model = lgb.LGBMRegressor(learning_rate = learning_rate, n_estimators = iterations, max_depth = depth)\n",
    "    \n",
    "    print('Training Time:')\n",
    "    %time LGBM_model.fit(features_train, target_train)\n",
    "    \n",
    "    print('Prediction Time:')\n",
    "    %time LGBM_prediction = LGBM_model.predict(features_valid)\n",
    "\n",
    "    print('RMSE: {:.0f}'.format(mean_squared_error(target_valid, LGBM_prediction)**0.5))\n",
    "    print('')\n",
    "    print('')\n",
    "    #Ensures the lowest RMSE and associated hyperparameters are stored in the 'best' variables\n",
    "    if mean_squared_error(target_valid, LGBM_prediction)**0.5 < best_LGBM_RMSE:\n",
    "        best_LGBM_RMSE = mean_squared_error(target_valid, LGBM_prediction)**0.5\n",
    "        best_LGBM_parameters = [learning_rate, iterations, depth]\n",
    "        \n",
    "print('The best RMSE is {:.0f}, which are from the following parameters - learning rate: {}, n-estimators: {}, max tree depth: {}'.format(best_LGBM_RMSE, best_LGBM_parameters[0], best_LGBM_parameters[1], best_LGBM_parameters[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best RMSE from the LightGBM models is 1775 which is for a `learning_rate` of 0.5, `n_estimators` of 100, and `max_depth` of 8. The higher `n_estimators` and `max_depth` resulted in generally high RMSEs. Reducing the `learning_rate` led to slightly faster model training and prediction times.\n",
    " \n",
    "**CatBoost**\n",
    "\n",
    "For the CatBoost model, similar to LightGBM, `learning_rate`, `iterations`, and `depth` are tuned for the hyperparameters. The same methodology is followed for returning the training and prediction time, and choosing the best model hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost with learning rate: 1.0, iterations: 100, tree depth: 10\n",
      "Training Time:\n",
      "0:\tlearn: 2493.5096534\ttotal: 347ms\tremaining: 34.4s\n",
      "50:\tlearn: 1617.4648741\ttotal: 23.4s\tremaining: 22.5s\n",
      "99:\tlearn: 1473.4394064\ttotal: 46.3s\tremaining: 0us\n",
      "CPU times: user 43.6 s, sys: 3.37 s, total: 47 s\n",
      "Wall time: 48.1 s\n",
      "Prediction Time:\n",
      "CPU times: user 123 ms, sys: 17.3 ms, total: 140 ms\n",
      "Wall time: 88 ms\n",
      "RMSE: 1857\n",
      "\n",
      "\n",
      "CatBoost with learning rate: 1.0, iterations: 100, tree depth: 8\n",
      "Training Time:\n",
      "0:\tlearn: 2600.1334909\ttotal: 392ms\tremaining: 38.8s\n",
      "50:\tlearn: 1744.3510120\ttotal: 19.9s\tremaining: 19.1s\n",
      "99:\tlearn: 1628.6987178\ttotal: 38.5s\tremaining: 0us\n",
      "CPU times: user 35.6 s, sys: 3.73 s, total: 39.4 s\n",
      "Wall time: 40.4 s\n",
      "Prediction Time:\n",
      "CPU times: user 101 ms, sys: 4.05 ms, total: 105 ms\n",
      "Wall time: 53.4 ms\n",
      "RMSE: 1835\n",
      "\n",
      "\n",
      "CatBoost with learning rate: 1.0, iterations: 100, tree depth: 6\n",
      "Training Time:\n",
      "0:\tlearn: 2734.2885317\ttotal: 225ms\tremaining: 22.3s\n",
      "50:\tlearn: 1841.4447441\ttotal: 15.3s\tremaining: 14.7s\n",
      "99:\tlearn: 1755.2462240\ttotal: 29.8s\tremaining: 0us\n",
      "CPU times: user 27.6 s, sys: 2.99 s, total: 30.6 s\n",
      "Wall time: 31.5 s\n",
      "Prediction Time:\n",
      "CPU times: user 99.8 ms, sys: 0 ns, total: 99.8 ms\n",
      "Wall time: 60 ms\n",
      "RMSE: 1834\n",
      "\n",
      "\n",
      "CatBoost with learning rate: 1.0, iterations: 50, tree depth: 10\n",
      "Training Time:\n",
      "0:\tlearn: 2493.5096534\ttotal: 501ms\tremaining: 24.6s\n",
      "49:\tlearn: 1623.4860033\ttotal: 23.2s\tremaining: 0us\n",
      "CPU times: user 22.2 s, sys: 1.68 s, total: 23.9 s\n",
      "Wall time: 24.9 s\n",
      "Prediction Time:\n",
      "CPU times: user 114 ms, sys: 4.16 ms, total: 118 ms\n",
      "Wall time: 70.1 ms\n",
      "RMSE: 1847\n",
      "\n",
      "\n",
      "CatBoost with learning rate: 1.0, iterations: 50, tree depth: 8\n",
      "Training Time:\n",
      "0:\tlearn: 2600.1334909\ttotal: 387ms\tremaining: 19s\n",
      "49:\tlearn: 1747.6179168\ttotal: 19.7s\tremaining: 0us\n",
      "CPU times: user 18.5 s, sys: 1.86 s, total: 20.3 s\n",
      "Wall time: 21.4 s\n",
      "Prediction Time:\n",
      "CPU times: user 97.6 ms, sys: 191 µs, total: 97.8 ms\n",
      "Wall time: 62.6 ms\n",
      "RMSE: 1857\n",
      "\n",
      "\n",
      "CatBoost with learning rate: 1.0, iterations: 50, tree depth: 6\n",
      "Training Time:\n",
      "0:\tlearn: 2734.2885317\ttotal: 268ms\tremaining: 13.1s\n",
      "49:\tlearn: 1842.3843104\ttotal: 14.7s\tremaining: 0us\n",
      "CPU times: user 14.3 s, sys: 1.32 s, total: 15.6 s\n",
      "Wall time: 16.5 s\n",
      "Prediction Time:\n",
      "CPU times: user 84.6 ms, sys: 3.93 ms, total: 88.5 ms\n",
      "Wall time: 50.5 ms\n",
      "RMSE: 1874\n",
      "\n",
      "\n",
      "CatBoost with learning rate: 0.5, iterations: 100, tree depth: 10\n",
      "Training Time:\n",
      "0:\tlearn: 3124.9276843\ttotal: 322ms\tremaining: 31.8s\n",
      "50:\tlearn: 1667.8757080\ttotal: 23.6s\tremaining: 22.7s\n",
      "99:\tlearn: 1556.2599183\ttotal: 46.3s\tremaining: 0us\n",
      "CPU times: user 44 s, sys: 3.06 s, total: 47.1 s\n",
      "Wall time: 48.2 s\n",
      "Prediction Time:\n",
      "CPU times: user 138 ms, sys: 4.09 ms, total: 142 ms\n",
      "Wall time: 90.4 ms\n",
      "RMSE: 1764\n",
      "\n",
      "\n",
      "CatBoost with learning rate: 0.5, iterations: 100, tree depth: 8\n",
      "Training Time:\n",
      "0:\tlearn: 3188.6078104\ttotal: 313ms\tremaining: 31s\n",
      "50:\tlearn: 1763.1105457\ttotal: 19.6s\tremaining: 18.8s\n",
      "99:\tlearn: 1671.2685544\ttotal: 38.2s\tremaining: 0us\n",
      "CPU times: user 35.2 s, sys: 3.85 s, total: 39 s\n",
      "Wall time: 40.3 s\n",
      "Prediction Time:\n",
      "CPU times: user 95.8 ms, sys: 8.88 ms, total: 105 ms\n",
      "Wall time: 54.2 ms\n",
      "RMSE: 1773\n",
      "\n",
      "\n",
      "CatBoost with learning rate: 0.5, iterations: 100, tree depth: 6\n",
      "Training Time:\n",
      "0:\tlearn: 3271.5411046\ttotal: 218ms\tremaining: 21.6s\n",
      "50:\tlearn: 1844.4998508\ttotal: 15.4s\tremaining: 14.8s\n",
      "99:\tlearn: 1773.3913042\ttotal: 29.7s\tremaining: 0us\n",
      "CPU times: user 27.5 s, sys: 2.86 s, total: 30.4 s\n",
      "Wall time: 31.4 s\n",
      "Prediction Time:\n",
      "CPU times: user 91.6 ms, sys: 4.46 ms, total: 96.1 ms\n",
      "Wall time: 51.7 ms\n",
      "RMSE: 1804\n",
      "\n",
      "\n",
      "CatBoost with learning rate: 0.5, iterations: 50, tree depth: 10\n",
      "Training Time:\n",
      "0:\tlearn: 3124.9276843\ttotal: 384ms\tremaining: 18.8s\n",
      "49:\tlearn: 1672.8719098\ttotal: 22.8s\tremaining: 0us\n",
      "CPU times: user 22.1 s, sys: 1.54 s, total: 23.6 s\n",
      "Wall time: 24.6 s\n",
      "Prediction Time:\n",
      "CPU times: user 110 ms, sys: 7.82 ms, total: 118 ms\n",
      "Wall time: 56.7 ms\n",
      "RMSE: 1791\n",
      "\n",
      "\n",
      "CatBoost with learning rate: 0.5, iterations: 50, tree depth: 8\n",
      "Training Time:\n",
      "0:\tlearn: 3188.6078104\ttotal: 365ms\tremaining: 17.9s\n",
      "49:\tlearn: 1764.9942921\ttotal: 19.3s\tremaining: 0us\n",
      "CPU times: user 18.2 s, sys: 1.95 s, total: 20.2 s\n",
      "Wall time: 21.2 s\n",
      "Prediction Time:\n",
      "CPU times: user 101 ms, sys: 4.54 ms, total: 106 ms\n",
      "Wall time: 85 ms\n",
      "RMSE: 1811\n",
      "\n",
      "\n",
      "CatBoost with learning rate: 0.5, iterations: 50, tree depth: 6\n",
      "Training Time:\n",
      "0:\tlearn: 3271.5411046\ttotal: 217ms\tremaining: 10.6s\n",
      "49:\tlearn: 1846.4318278\ttotal: 15s\tremaining: 0us\n",
      "CPU times: user 14.3 s, sys: 1.5 s, total: 15.8 s\n",
      "Wall time: 16.7 s\n",
      "Prediction Time:\n",
      "CPU times: user 94.5 ms, sys: 115 µs, total: 94.7 ms\n",
      "Wall time: 63.3 ms\n",
      "RMSE: 1851\n",
      "\n",
      "\n",
      "The best RMSE is 1764, which are from the following parameters - learning rate: 0.5, iterations: 100, tree depth: 10\n"
     ]
    }
   ],
   "source": [
    "#Creates tuples of the various hyperparameter combinations\n",
    "CB_params = [(learning_rate, iterations, depth) for learning_rate in [x/2 for x in range(1, 3)] for iterations in range(50, 101, 50) for depth in range(6, 11, 2)]\n",
    "\n",
    "#Sets initial values for the best score and parameters\n",
    "best_CB_parameters = [0, 0, 0]\n",
    "best_CB_RMSE = baseline_RMSE\n",
    "\n",
    "#Loops through each combination of hyperparameters. For each combination, the training time and prediction time for the model\n",
    "#is printed. RMSE is determined from the validation set\n",
    "for learning_rate, iterations, depth in reversed(CB_params):\n",
    "    print('CatBoost with learning rate: {}, iterations: {}, tree depth: {}'.format(learning_rate, iterations, depth))\n",
    "\n",
    "    CB_model = CatBoostRegressor(loss_function = 'RMSE', learning_rate = learning_rate, iterations = iterations, depth = depth, verbose = 50)\n",
    "    \n",
    "    print('Training Time:')\n",
    "    %time CB_model.fit(features_train, target_train, cat_features = categorical_features)\n",
    "    \n",
    "    print('Prediction Time:')\n",
    "    %time CB_prediction = CB_model.predict(features_valid)\n",
    "\n",
    "    print('RMSE: {:.0f}'.format(mean_squared_error(target_valid, CB_prediction)**0.5))\n",
    "    print('')\n",
    "    print('')\n",
    "    if mean_squared_error(target_valid, CB_prediction)**0.5 < best_CB_RMSE:\n",
    "        best_CB_RMSE = mean_squared_error(target_valid, CB_prediction)**0.5\n",
    "        best_CB_parameters = [learning_rate, iterations, depth]\n",
    "        \n",
    "print('The best RMSE is {:.0f}, which are from the following parameters - learning rate: {}, iterations: {}, tree depth: {}'.format(best_CB_RMSE, best_CB_parameters[0], best_CB_parameters[1], best_CB_parameters[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CatBoost model has a slightly better, but similar RMSE of 1764 with a similar set of hyperparameters of `learning_rate` of 0.5, `iterations` of 100, but `depth` of 10. However, the model training times were generally quite a bit longer by almost half a minute.\n",
    "\n",
    "**XGBoost**\n",
    "\n",
    "The XGBoost model was tested initially, but took significantly longer than either of the other two types of models, therefore, the results of only varying one hyperparameter will be presented to get an understanding of how it affected the run time and quality. Since quality is only one of the three grading criteria, with speed being two of them, this type of model can be eliminated as a potential selection.\n",
    "\n",
    "`colsample_bytree` was the hyperparameter varied. Varying this hyperparameter varies how many of the features are used in training the model. This parameter was selected to evaluate how it affects the training speed, as well as the quality to determine if it is necessary to use all of the features for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost with colsample_bytree: 0.5\n",
      "Training Time:\n",
      "CPU times: user 1min 46s, sys: 1.48 s, total: 1min 48s\n",
      "Wall time: 1min 50s\n",
      "Prediction Time:\n",
      "CPU times: user 648 ms, sys: 252 ms, total: 900 ms\n",
      "Wall time: 903 ms\n",
      "RMSE: 2059\n",
      "\n",
      "\n",
      "XGBoost with colsample_bytree: 1\n",
      "Training Time:\n",
      "CPU times: user 2min 47s, sys: 1.45 s, total: 2min 48s\n",
      "Wall time: 2min 52s\n",
      "Prediction Time:\n",
      "CPU times: user 686 ms, sys: 247 ms, total: 933 ms\n",
      "Wall time: 936 ms\n",
      "RMSE: 2054\n",
      "\n",
      "\n",
      "The best RMSE is 2054, which is from a colsample_bytree of 1\n"
     ]
    }
   ],
   "source": [
    "#Sets initial values for the best score and parameters\n",
    "best_XGB_colsample_bytree = 0\n",
    "best_XGB_RMSE = baseline_RMSE\n",
    "\n",
    "#Loops through each hyperparameter value. The training time and prediction time for the model\n",
    "#is printed. RMSE is determined from the validation set\n",
    "for colsample_bytree in (0.5, 1):\n",
    "    print('XGBoost with colsample_bytree: {}'.format(colsample_bytree))\n",
    "\n",
    "    XGB_model = xgb.XGBRegressor(colsample_bytree = colsample_bytree, objective = 'reg:squarederror')\n",
    "    print('Training Time:')\n",
    "    %time XGB_model.fit(features_train_ohe, target_train_ohe)\n",
    "    \n",
    "    print('Prediction Time:')\n",
    "    %time XGB_prediction = XGB_model.predict(features_valid_ohe)\n",
    "\n",
    "    print('RMSE: {:.0f}'.format(mean_squared_error(target_valid_ohe, XGB_prediction)**0.5))\n",
    "    print('')\n",
    "    print('')\n",
    "    if mean_squared_error(target_valid, XGB_prediction)**0.5 < best_XGB_RMSE:\n",
    "        best_XGB_RMSE = mean_squared_error(target_valid, XGB_prediction)**0.5\n",
    "        best_XGB_colsample_bytree = colsample_bytree\n",
    "        \n",
    "print('The best RMSE is {:.0f}, which is from a colsample_bytree of {}'.format(best_XGB_RMSE, best_XGB_colsample_bytree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a `colsample_bytree` value of 0.5 as opposed to 1 improves the processing time by a minute while still maintaining a similar RMSE. The theory that using less of the features seems to be true.\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "All of the gradient boosting models were significantly better than the linear regression or decision tree models (~1800-2000 compared to ~2200 - 3100). The LightGBM and CatBoost models were similar quality and times, with CatBoost being slightly higher quality but sacrificing a fair amount of training time. The XGBoost had a much slower time and higher quality, although these could probably be better optimized with further hyperparameter tuning. For the final model selection, the LightGBM model will be selected mainly due to the faster training time. The hyperparameters for this model will be further tuned in hopes of improving the model quality even further without sacrificing a significant amount of training time\n",
    "\n",
    "<a id='Model Analysis'></a>\n",
    "## Model Analysis\n",
    "\n",
    "Since it was determined from the initial hyperparameter tuning that `learning_rate` and `n_estimators` have a noticeable impact on model quality, these hyperparameters will be more drastically tuned in an attempt to get a higher model quality. The model training time will be printed for the best hyperparameters as a check to ensure that it isn't a significant increase in time that is not worth the increase of model quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best RMSE is 1699, which are from the following parameters - learning rate: 0.2, n-estimators: 500, max tree depth: 8\n",
      "CPU times: user 6.34 s, sys: 61.5 ms, total: 6.41 s\n",
      "Wall time: 6.41 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.2, max_depth=8,\n",
       "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=500, n_jobs=-1, num_leaves=31, objective=None,\n",
       "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creates tuples of the various hyperparameter combinations\n",
    "LGBM_params = [(learning_rate, iterations, depth) for learning_rate in [x/10 for x in range(1, 4)] for iterations in range(300, 501, 100) for depth in range(6, 11, 2)]\n",
    "\n",
    "#Sets initial values for the best score and parameters\n",
    "best_LGBM_parameters = [0, 0, 0]\n",
    "best_LGBM_RMSE = baseline_RMSE\n",
    "\n",
    "#Loops through each combination of hyperparameters. For each combination, the training time and prediction time for the model\n",
    "#is printed. RMSE is determined from the validation set\n",
    "for learning_rate, iterations, depth in reversed(LGBM_params):\n",
    "    \n",
    "    LGBM_model = lgb.LGBMRegressor(learning_rate = learning_rate, n_estimators = iterations, max_depth = depth)\n",
    "    \n",
    "    LGBM_model.fit(features_train, target_train)\n",
    "    \n",
    "    LGBM_prediction = LGBM_model.predict(features_valid)\n",
    "\n",
    "    if mean_squared_error(target_valid, LGBM_prediction)**0.5 < best_LGBM_RMSE:\n",
    "        best_LGBM_RMSE = mean_squared_error(target_valid, LGBM_prediction)**0.5\n",
    "        best_LGBM_parameters = [learning_rate, iterations, depth]\n",
    "        \n",
    "print('The best RMSE is {:.0f}, which are from the following parameters - learning rate: {}, n-estimators: {}, max tree depth: {}'.format(best_LGBM_RMSE, best_LGBM_parameters[0], best_LGBM_parameters[1], best_LGBM_parameters[2]))\n",
    "\n",
    "#Prints time of the best model\n",
    "LGBM_model = lgb.LGBMRegressor(learning_rate = best_LGBM_parameters[0], n_estimators = best_LGBM_parameters[1], max_depth = best_LGBM_parameters[2])\n",
    "%time LGBM_model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model quality did improve slightly from 1775 to 1699 while only taking a few extra seconds to train, a worthwhile improvement. The hyperparameters of `learning_rate`: 0.2, `n_estimators`: 500, and `max_depth`: 8 will be used to train the final model to test against the testing dataset.\n",
    "\n",
    "### Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time:\n",
      "CPU times: user 6.4 s, sys: 66.9 ms, total: 6.47 s\n",
      "Wall time: 6.48 s\n",
      "Prediction Time:\n",
      "CPU times: user 2.83 s, sys: 36 µs, total: 2.83 s\n",
      "Wall time: 2.84 s\n",
      "The RMSE for the selected model when evaluated against the testing dataset is 1714.\n"
     ]
    }
   ],
   "source": [
    "#Creates a final LightGBM model using the ideal hyperparameters\n",
    "final_model = lgb.LGBMRegressor(learning_rate = 0.2, n_estimators = 500, max_depth = 8)\n",
    "\n",
    "print('Training Time:')\n",
    "%time final_model.fit(features_train, target_train)\n",
    "\n",
    "#Tests model against the testing dataset\n",
    "print('Prediction Time:')\n",
    "%time test_prediction = final_model.predict(features_test)\n",
    "\n",
    "print('The RMSE for the selected model when evaluated against the testing dataset is {:.0f}.'.format(mean_squared_error(target_test, test_prediction)**0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE for the LightGBM model with the chosen hyperparameters is 1714 while only taking a training time of 6.48s and a prediction time of 2.84s when evaluated against the testing dataset. \n",
    "\n",
    "### Feature Importance\n",
    "\n",
    "Early speculation showed that reducing the number of features for the model training generally did not have a noticeable effect on the model quality. The feature importance is shown in the graph below and verifies that 4 main features dominate the features that are the most important in determining the final price of the vehicle. Four of the features have nearly no effect, with `NumberOfPictures` having no relevance.\n",
    "\n",
    "If desired, this information could be used to further speed up the training of the model by only passing the features with the most importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa89f98b990>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot feature important for the final model\n",
    "lgb.plot_importance(final_model, title = 'LightGBM Model Feature Importance', ignore_zero = False, grid = False, figsize = (12,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Overall Conclusion'></a>\n",
    "## Overall Conclusion\n",
    "\n",
    "The purpose of this project was to develop a model to determine the value of a car based on various information from a car sales ad. The model was required to balance out prediction quality, model training time, and prediction time.\n",
    "\n",
    "The data was downloaded and preprocessed, notably OHE several categorical features for use in the various types of models. A linear regression model was trained and the quality of it was used as a baseline model to sanity check the other models. Three different gradient boosting models were evaluated: LightGBM, CatBoost, and XGBoost. Hyperparameters for each of these models were tuned and model quality, training times, and prediction times were evaluated for each.\n",
    "\n",
    "The LightGBM model was selected for the final model due to its acceptable model quality and fast training time. The hyperparameters for the LightGBM model were even further tuned, leading to an optimal set of hyperparameters that were tested against the testing dataset for a model RMSE of 1714, a training time of 6.5s and a prediction time of 2.8s."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
