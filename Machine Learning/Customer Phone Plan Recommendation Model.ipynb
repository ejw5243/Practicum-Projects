{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MegaLine Subscriber Plan Prediction\n",
    "\n",
    "## Purpose\n",
    "\n",
    "The purpose of this project is to develop a model that will most accurately predict whether a customer uses the Smart or Ultra plans with an accuracy of at least 75%. This model will be utilized to recommend one of the two plans to future customers that best suit their monthly usage.\n",
    "\n",
    "## Table of Contents\n",
    "<a href='#General Data Information'>General Data Information</a>\n",
    "\n",
    "<a href='#Model Development'>Model Development</a>\n",
    "\n",
    "<a href='#Dataset Separation'>Dataset Separation</a>\n",
    "\n",
    "<a href='#Model Training'>Model Training</a>\n",
    "\n",
    "<a href='#Model Testing'>Model Testing</a>\n",
    "\n",
    "<a href='#Overall Conclusion'>Overall Conclusion</a>\n",
    "\n",
    "<a id='General Data Information'></a>\n",
    "## General Data Information\n",
    "\n",
    "Initially, a general look at the data is performed and the necessary sklearn modules are imported. Since the target attribute is categorical (either ultra or not ultra), classification modules are imported for Decision Tree, Random Forest, and Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries and modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sc\n",
    "from scipy import stats as st\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null float64\n",
      "minutes     3214 non-null float64\n",
      "messages    3214 non-null float64\n",
      "mb_used     3214 non-null float64\n",
      "is_ultra    3214 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data = pd.read_csv('/datasets/users_behavior.csv')\n",
    "\n",
    "user_data.info()\n",
    "\n",
    "user_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data was already preprocessed during a previous effort; therefore, it was not expected to have any missing values. This was verified and confirmed.\n",
    "\n",
    "<a id='Model Development'></a>\n",
    "## Model Development\n",
    "\n",
    "<a id='Dataset Separation'></a>\n",
    "### Dataset Separation\n",
    "\n",
    "Since there is only one dataset available, this must be separated into a training dataset, validation dataset, and testing dataset in order to build, validate, and test the models. The original dataset is split into a 3:1:1 ratio for the training, validating, and testing datasets, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits the original dataset into 60% training, 40% leftover\n",
    "user_train, user_valid_test = train_test_split(user_data, test_size = 0.4, random_state=12345)\n",
    "#Splits the leftover dataset into 50% validating, 50% testing for 20%/20% overall\n",
    "user_valid, user_test = train_test_split(user_valid_test, test_size = 0.5, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the goal of this model is to predict whether a customer is on the Ultra plan or not, the `is_ultra` attribute is set as the target, while the remainder of the attributes are selected as the features, as these all have an effect on whether a customer is on the Ultra plan or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates features and targets of each dataset\n",
    "features_train = user_train.drop('is_ultra', axis=1)\n",
    "target_train = user_train['is_ultra']\n",
    "\n",
    "features_valid = user_valid.drop('is_ultra', axis=1)\n",
    "target_valid = user_valid['is_ultra']\n",
    "\n",
    "features_test = user_test.drop('is_ultra', axis=1)\n",
    "target_test = user_test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the training, validating, and testing datasets created, and targets and features defined for each, various models can now be trained and their accuracies compared.\n",
    "\n",
    "<a id='Model Training'></a>\n",
    "### Model Training\n",
    "\n",
    "Three different forms of classification models will be trained: Logistic Regression, Decision Tree, and Random Forest. For each model, various hyperparameters will be altered to create the most accurate model for each. All models are trained with the training dataset and then the accuracy is determined against the validation dataset.\n",
    "\n",
    "#### Logistic Regression Model\n",
    "\n",
    "For the logistic regression model, two hyperparameters will be altered: the `C` parameter (inverse regularization) and the `penalty` parameter. For the C parameter, a range of regularization values from very small (0.01) to very large (100) are selected, including 1 (neutral) to determine how it affects overfitting. For the penalty parameter, Lasso Regression (l1) and Ridge Regression (l2) are the two options evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C Value: 0.01   Penalty: l1   Accuracy: 0.711\n",
      "C Value: 0.01   Penalty: l2   Accuracy: 0.725\n",
      "\n",
      "C Value: 0.1   Penalty: l1   Accuracy: 0.757\n",
      "C Value: 0.1   Penalty: l2   Accuracy: 0.748\n",
      "\n",
      "C Value: 0.5   Penalty: l1   Accuracy: 0.757\n",
      "C Value: 0.5   Penalty: l2   Accuracy: 0.756\n",
      "\n",
      "C Value: 1   Penalty: l1   Accuracy: 0.756\n",
      "C Value: 1   Penalty: l2   Accuracy: 0.759\n",
      "\n",
      "C Value: 10   Penalty: l1   Accuracy: 0.756\n",
      "C Value: 10   Penalty: l2   Accuracy: 0.708\n",
      "\n",
      "C Value: 100   Penalty: l1   Accuracy: 0.756\n",
      "C Value: 100   Penalty: l2   Accuracy: 0.756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loops through 6 different c values and 2 different regression regularizations and outputs the accuracy of them\n",
    "for c_value in [0.01, 0.1, 0.5, 1, 10, 100]:\n",
    "    for penalty in ['l1','l2']:\n",
    "        logistic_regression_model = LogisticRegression(random_state = 12345, penalty=penalty, C = c_value, solver = 'liblinear')\n",
    "        logistic_regression_model.fit(features_train, target_train)\n",
    "        logistic_regression_accuracy = logistic_regression_model.score(features_valid, target_valid)\n",
    "        print(\"C Value:\", c_value, \"  Penalty:\", penalty, \"  Accuracy: {:.3f}\".format(logistic_regression_accuracy))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the various logistic regression models trained, the neutral C value Ridge Regression had the best accuracy. However, for C values 0.1 and greater, and for either regularization technique, the accuracies are all close together, showing very little variation from changing the two hyperparameters. The exception to this for a model with a C value of 10 for the Ridge Regression which has a significantly lower accuracy than the rest of the models. This is likely an anomaly with the model/data.\n",
    "\n",
    "#### Decision Tree Model\n",
    "\n",
    "For the Decision Tree model, two hyperparameters will be altered: the `max_depth` parameter and the `min_samples_leaf` parameter. For the `max_depth` values from 1 to 7 were used and for the `min_samples_leaf` parameter, values of 1 and 2 were used to determine the effects on model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 1   min_leaf_sample: 1   Accuracy: 0.754\n",
      "max_depth: 1   min_leaf_sample: 2   Accuracy: 0.754\n",
      "\n",
      "max_depth: 2   min_leaf_sample: 1   Accuracy: 0.782\n",
      "max_depth: 2   min_leaf_sample: 2   Accuracy: 0.782\n",
      "\n",
      "max_depth: 3   min_leaf_sample: 1   Accuracy: 0.785\n",
      "max_depth: 3   min_leaf_sample: 2   Accuracy: 0.785\n",
      "\n",
      "max_depth: 4   min_leaf_sample: 1   Accuracy: 0.779\n",
      "max_depth: 4   min_leaf_sample: 2   Accuracy: 0.779\n",
      "\n",
      "max_depth: 5   min_leaf_sample: 1   Accuracy: 0.779\n",
      "max_depth: 5   min_leaf_sample: 2   Accuracy: 0.778\n",
      "\n",
      "max_depth: 6   min_leaf_sample: 1   Accuracy: 0.784\n",
      "max_depth: 6   min_leaf_sample: 2   Accuracy: 0.779\n",
      "\n",
      "max_depth: 7   min_leaf_sample: 1   Accuracy: 0.782\n",
      "max_depth: 7   min_leaf_sample: 2   Accuracy: 0.784\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loops through a max_depth from 1 to 7 and a min_samples_leaf of 1 or 2. Calculates accuracy for each\n",
    "for depth in range (1,8):\n",
    "    for leaf in range(1,3):\n",
    "        decision_tree_model = DecisionTreeClassifier(max_depth=depth, min_samples_leaf=leaf, random_state=12345)\n",
    "        decision_tree_model.fit(features_train, target_train)\n",
    "        decision_tree_accuracy = decision_tree_model.score(features_valid, target_valid)\n",
    "        print(\"max_depth:\",depth,\"  min_leaf_sample:\", leaf, \"  Accuracy: {:.3f}\".format(decision_tree_accuracy))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with the exception of a `max_depth` of 1, the accuracy of the various models were all fairly similar, with a `max_depth` of 3 having the highest accuracy, regardless of the `min_leaf_sample`. These models generally proved to be more accurate than the logistic regression models.\n",
    "\n",
    "#### Random Forest Model\n",
    "\n",
    "For the Random Forest model, two hyperparameters will be altered: the `n_estimators` parameter and the `max_depth` parameter. The number of trees (`n_estimators`) varied from 10 to 50 in increments of 10. The `max_depth` parameter varied from 2 to 10 in increments of 2 since the Decision Tree model showed little variation between changes to the max_depth past the first depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 10   max_depth: 2   Accuracy: 0.778\n",
      "n_estimators: 10   max_depth: 4   Accuracy: 0.790\n",
      "n_estimators: 10   max_depth: 6   Accuracy: 0.801\n",
      "n_estimators: 10   max_depth: 8   Accuracy: 0.796\n",
      "n_estimators: 10   max_depth: 10   Accuracy: 0.792\n",
      "\n",
      "n_estimators: 20   max_depth: 2   Accuracy: 0.784\n",
      "n_estimators: 20   max_depth: 4   Accuracy: 0.788\n",
      "n_estimators: 20   max_depth: 6   Accuracy: 0.799\n",
      "n_estimators: 20   max_depth: 8   Accuracy: 0.798\n",
      "n_estimators: 20   max_depth: 10   Accuracy: 0.792\n",
      "\n",
      "n_estimators: 30   max_depth: 2   Accuracy: 0.784\n",
      "n_estimators: 30   max_depth: 4   Accuracy: 0.787\n",
      "n_estimators: 30   max_depth: 6   Accuracy: 0.801\n",
      "n_estimators: 30   max_depth: 8   Accuracy: 0.799\n",
      "n_estimators: 30   max_depth: 10   Accuracy: 0.795\n",
      "\n",
      "n_estimators: 40   max_depth: 2   Accuracy: 0.785\n",
      "n_estimators: 40   max_depth: 4   Accuracy: 0.790\n",
      "n_estimators: 40   max_depth: 6   Accuracy: 0.802\n",
      "n_estimators: 40   max_depth: 8   Accuracy: 0.809\n",
      "n_estimators: 40   max_depth: 10   Accuracy: 0.796\n",
      "\n",
      "n_estimators: 50   max_depth: 2   Accuracy: 0.784\n",
      "n_estimators: 50   max_depth: 4   Accuracy: 0.787\n",
      "n_estimators: 50   max_depth: 6   Accuracy: 0.799\n",
      "n_estimators: 50   max_depth: 8   Accuracy: 0.807\n",
      "n_estimators: 50   max_depth: 10   Accuracy: 0.793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loops through n_estimators of 10, 20, 30, 40, and 50, and max_depth of 2, 4, 6, 8, and 10. Calculates accuracy for each\n",
    "for tree in range(10, 51, 10):\n",
    "    for depth in range(2, 11, 2):\n",
    "        random_forest_model = RandomForestClassifier(n_estimators = tree, max_depth = depth, random_state=12345)\n",
    "        random_forest_model.fit(features_train, target_train)\n",
    "        random_forest_accuracy = random_forest_model.score(features_valid, target_valid)\n",
    "        print(\"n_estimators:\", tree, '  max_depth:', depth, '  Accuracy: {:.3f}'.format(random_forest_accuracy))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Random Forest models, models that had a higher number of trees generally had higher accuracies, although the impact was not significant. For the `max_depth` highest accuracies at the 6 and 8 values were generally observed. The most accurate model was one with 40 trees and a `max_depth` of 8.\n",
    "\n",
    "#### Model Conclusion\n",
    "\n",
    "From the three types of models trained, logistic regression models had the lowest accuracy at roughly 71-76%, with Decision Tree having the next highest at 75-78%, and Random Forest having the best accuracy at 78-80%. Random Forest had the most consistent results with little variation between the parameters chosen, whereas logistic regression had the highest variation in accuracy. The Random Forest model with 40 trees and a `max_depth` of 8 had the best accuracy, at 80.8%. This model will be selected for the testing dataset.\n",
    "\n",
    "<a id='Model Testing'></a>\n",
    "### Model Testing\n",
    "\n",
    "The most accurate Random Forest model from the training and validating dataset will now be tested with the testing dataset using the same hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 79.6%.\n"
     ]
    }
   ],
   "source": [
    "#Calculate accuracy of the Random Forest Model using the testing dataset. Hyperparameters of the most accurate model used.\n",
    "random_forest_model_test = RandomForestClassifier(n_estimators = 40, max_depth = 8, random_state=12345)\n",
    "random_forest_model_test.fit(features_train, target_train)\n",
    "random_forest_model_test_accuracy = random_forest_model_test.score(features_test, target_test)\n",
    "print(\"The accuracy of the model is {:.1%}.\".format(random_forest_model_test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the selected Random Forest model with the testing dataset resulted in an accuracy of 79.6%. This is within the range of accuracies that were predicted for the validation set, so it seems that the model has performed as expected. However, a sanity check will still be performed to verify.\n",
    "\n",
    "#### Model Sanity Check\n",
    "\n",
    "A sanity check of the model will be performed by using a Dummy Classifier with two separate strategies: a most frequent strategy that assumes each answer in the testing dataset is the most frequent response, and a stratified strategy that makes predictions based on the statistical distribution of the testing dataset. The accuracy of these two methods will be compared to the Random Forest model to ensure the model is working as expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the most frequent method is 68.4%\n"
     ]
    }
   ],
   "source": [
    "most_frequent_test = DummyClassifier(strategy = 'most_frequent', random_state=12345)\n",
    "most_frequent_test.fit(features_train, target_train)\n",
    "most_frequent_test_accuracy = most_frequent_test.score(features_test, target_test)\n",
    "print(\"The accuracy of the most frequent method is {:.1%}\".format(most_frequent_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the stratified frequent method is 53.7%\n"
     ]
    }
   ],
   "source": [
    "stratified_test = DummyClassifier(strategy = 'stratified', random_state=12345)\n",
    "stratified_test.fit(features_train, target_train)\n",
    "stratified_test_accuracy = stratified_test.score(features_test, target_test)\n",
    "print(\"The accuracy of the stratified frequent method is {:.1%}\".format(stratified_test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracies of the most frequent and stratified dummy classifiers are 68.4% and 53.7%, respectively. This is well below the selected Random Forest model accuracy of 79.6% which confirms that the Random Forest Model is working as intended. \n",
    "\n",
    "<a id='Overall Conclusion'></a>\n",
    "## Overall Conclusion\n",
    "\n",
    "The purpose of this project is to develop a model that will most accurately predict whether a customer uses the Smart of Ultra plans based on previously provided data. The available data was split into three different datasets: training, validating, and testing datasets. Three separate classification models, Logistic Regression, Decision Tree, and Random Forest, were trained with varying hyperparameters on the training dataset. The accuracy of each of the model iterations were then calculated against the validating dataset.\n",
    "\n",
    "The Random Forest models had the highest accuracy, closely followed by the Decision Tree models. Using the tuned hyperparameters, a model with 79.8% accuracy on the testing dataset was developed. This model was validated to be working correctly by performing two sanity checks on the testing dataset with a dummy classifier.\n",
    "\n",
    "Using a Random Forest model with hyperparameters of 40 `n_estimators` and a `max_depth` of 8 will provide the best accuracy for the data in question and meet the accuracy requirement of 75%. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
